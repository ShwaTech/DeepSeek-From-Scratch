{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ELgyIhXFWu8"
      },
      "source": [
        "## IMPLEMENTING SELF ATTENTION WITH TRAINABLE WEIGHTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyNsCaxsFWu8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89, 0.17, 0.23, 0.19, 0.38, 0.44],  # The       (x^1)\n",
        "   [0.55, 0.87, 0.66, 0.51, 0.49, 0.3, 0.2, 0.1],     # next      (x^2)\n",
        "   [0.57, 0.85, 0.64, 0.8, 0.1, 0.4, 0.21, 0.39],     # day       (x^3)\n",
        "   [0.22, 0.58, 0.33, 0.4, 0.4, 0.4, 0.1, 0.3],       # is        (x^4)\n",
        "   [0.77, 0.25, 0.10, 0.1, 0.9, 0.3, 0.3, 0.2]]       # bright    (x^5)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcsGz3amFWu8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's begin by defining a few variables:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E4fGXRBFWu8"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "A: The second input element\n",
        "\n",
        "B: The input embedding size, d=8\n",
        "\n",
        "C: The output embedding size, d_out=4\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "22Y3zmisFWu8"
      },
      "outputs": [],
      "source": [
        "x_2 = inputs[1] # A\n",
        "# What is x_2?\n",
        "# Input embedding for the \"next\" word\n",
        "\n",
        "d_in = inputs.shape[1] # B\n",
        "d_out = 4 # C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpRafd7rn54Y",
        "outputId": "11fcc207-61ed-4116-c394-aa7641a9a548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5500, 0.8700, 0.6600, 0.5100, 0.4900, 0.3000, 0.2000, 0.1000])\n",
            "8\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "print(x_2)\n",
        "print(d_in)\n",
        "print(d_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG8AFnvhFWu8"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Note that in GPT-like models, the input and output dimensions are usually the same.\n",
        "\n",
        "But for illustration purposes, to better follow the computation, we choose different input (d_in=3)\n",
        "and output (d_out=2) dimensions here.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp0cgiTBFWu8"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we initialize the three weight matrices Wq, Wk and Wv\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Jc09QozZFWu8"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk-fB9HoFWu8",
        "outputId": "2e2bc6b1-851b-4ee1-da26-633b8bf40d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
            "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
            "        [0.1841, 0.7264, 0.3153, 0.6871],\n",
            "        [0.0756, 0.1966, 0.3164, 0.4017],\n",
            "        [0.1186, 0.8274, 0.3821, 0.6605],\n",
            "        [0.8536, 0.5932, 0.6367, 0.9826],\n",
            "        [0.2745, 0.6584, 0.2775, 0.8573],\n",
            "        [0.8993, 0.0390, 0.9268, 0.7388]])\n"
          ]
        }
      ],
      "source": [
        "print(W_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvpnCqkqFWu8",
        "outputId": "ff6f2533-4c2d-4c8d-bac8-0c743b3ea047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.7179, 0.7058, 0.9156, 0.4340],\n",
            "        [0.0772, 0.3565, 0.1479, 0.5331],\n",
            "        [0.4066, 0.2318, 0.4545, 0.9737],\n",
            "        [0.4606, 0.5159, 0.4220, 0.5786],\n",
            "        [0.9455, 0.8057, 0.6775, 0.6087],\n",
            "        [0.6179, 0.6932, 0.4354, 0.0353],\n",
            "        [0.1908, 0.9268, 0.5299, 0.0950],\n",
            "        [0.5789, 0.9131, 0.0275, 0.1634]])\n"
          ]
        }
      ],
      "source": [
        "print(W_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LswkRLfqFWu9",
        "outputId": "6339f873-15b3-4b4a-f7b8-da20d52517f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.3009, 0.5201, 0.3834, 0.4451],\n",
            "        [0.0126, 0.7341, 0.9389, 0.8056],\n",
            "        [0.1459, 0.0969, 0.7076, 0.5112],\n",
            "        [0.7050, 0.0114, 0.4702, 0.8526],\n",
            "        [0.7320, 0.5183, 0.5983, 0.4527],\n",
            "        [0.2251, 0.3111, 0.1955, 0.9153],\n",
            "        [0.7751, 0.6749, 0.1166, 0.8858],\n",
            "        [0.6568, 0.8459, 0.3033, 0.6060]])\n"
          ]
        }
      ],
      "source": [
        "print(W_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC2AVYvQFWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Note that we are setting requires_grad=False to reduce clutter in the outputs for\n",
        "illustration purposes.\n",
        "\n",
        "If we were to use the weight matrices for model training, we\n",
        "would set requires_grad=True to update these matrices during model training.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZWD12zyFWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we compute the query, key, and value vectors as shown earlier\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opX2I50vFWu9",
        "outputId": "192e944e-d83a-4155-ad35-0448ed36cb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.8463, 2.3367, 1.1531, 1.9900])\n"
          ]
        }
      ],
      "source": [
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEHFD_98FWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "As we can see based on the output for the query, this results in a 4-dimensional vector.\n",
        "\n",
        "This is because: we set the number of columns of the corresponding weight matrix, via d_out, to 4:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veAsJ0NKFWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Even though our temporary goal is to only compute the one context vector z(2),  we still\n",
        "require the key and value vectors for all input elements.\n",
        "\n",
        "This is because they are involved in computing the attention weights with respect to the query q(2)\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KGgTgLkFWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "We can obtain all keys and values via matrix multiplication:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5NJAQhaFWu9",
        "outputId": "46f09fd7-a929-40a8-ff6d-ce7e55b89fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keys.shape: torch.Size([5, 4])\n",
            "values.shape: torch.Size([5, 4])\n",
            "queries.shape: torch.Size([5, 4])\n"
          ]
        }
      ],
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "queries = inputs @ W_query\n",
        "\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "\n",
        "print(\"values.shape:\", values.shape)\n",
        "\n",
        "print(\"queries.shape:\", queries.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRt92w1QFWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "As we can tell from the outputs, we successfully projected the 6 input tokens from a 3D\n",
        "onto a 2D embedding space:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFmiy33rFWu9"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "First, let's compute the attention score ω22</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AESq17PQFWu9",
        "outputId": "c997596f-eee3-4727-e720-12e4593a951e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(12.0370)\n"
          ]
        }
      ],
      "source": [
        "keys_2 = keys[1] # A\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCng8GQDFWu-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Again, we can generalize this computation to all attention scores via matrix multiplication:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmiHnuZ6FWu-",
        "outputId": "f47b2ad4-be24-4836-8b9c-1cbb2e0d1f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 9.7351, 12.0370, 12.2923,  8.7149, 10.9628])\n"
          ]
        }
      ],
      "source": [
        "attn_scores_2 = query_2 @ keys.T # All attention scores for given query\n",
        "print(attn_scores_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCW5Jd42FWu-",
        "outputId": "8bbdf78b-4391-412b-9142-607dfc28d4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 8.7252, 10.8803, 11.0007,  7.7678,  9.7598],\n",
            "        [ 9.7351, 12.0370, 12.2923,  8.7149, 10.9628],\n",
            "        [10.4691, 12.9987, 13.1878,  9.3438, 11.8256],\n",
            "        [ 7.7531,  9.6199,  9.7608,  6.9217,  8.7864],\n",
            "        [ 8.8185, 10.9612, 11.1314,  7.8699,  9.8633]])\n"
          ]
        }
      ],
      "source": [
        "attn_scores = queries @ keys.T # omega\n",
        "print(attn_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdJ8CtAXFWu-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "We compute the attention weights by scaling the\n",
        "attention scores and using the softmax function we used earlier.\n",
        "\n",
        "The difference to earlier is\n",
        "that we now scale the attention scores by dividing them by the square root of the\n",
        "embedding dimension of the keys.\n",
        "\n",
        "Note that taking the square root is mathematically the\n",
        "same as exponentiating by 0.5:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0WnYsqZFWu-",
        "outputId": "ed0c4a2b-6c8c-46b2-83dd-70d87ed415ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0980, 0.3099, 0.3521, 0.0589, 0.1811])\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "\n",
        "print(attn_weights_2)\n",
        "print(d_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DHefcmNpetd",
        "outputId": "f517cf67-391c-4ae8-e94d-8d27b0ae4249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.1069, 0.3140, 0.3335, 0.0662, 0.1793],\n",
            "        [0.0980, 0.3099, 0.3521, 0.0589, 0.1811],\n",
            "        [0.0911, 0.3227, 0.3547, 0.0519, 0.1795],\n",
            "        [0.1162, 0.2954, 0.3170, 0.0767, 0.1947],\n",
            "        [0.1063, 0.3103, 0.3379, 0.0662, 0.1793]])\n",
            "\n",
            "Sum of Each Row:\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ],
      "source": [
        "attn_weights_final = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
        "print(attn_weights_final)\n",
        "\n",
        "row_sums = attn_weights_final.sum(dim=1)\n",
        "print(\"\\nSum of Each Row:\")\n",
        "print(row_sums)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TgEk_m2FWu-"
      },
      "source": [
        "## WHY DIVIDE BY SQRT (DIMENSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLFM7HvWFWu-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Reason 1: For stability in learning\n",
        "\n",
        "The softmax function is sensitive to the magnitudes of its inputs. When the inputs are large, the differences between the exponential values of each input become much more pronounced. This causes the softmax output to become \"peaky,\" where the highest value receives almost all the probability mass, and the rest receive very little.\n",
        "\n",
        "In attention mechanisms, particularly in transformers, if the dot products between query and key vectors become too large (like multiplying by 8 in this example), the attention scores can become very large. This results in a very sharp softmax distribution, making the model overly confident in one particular \"key.\" Such sharp distributions can make learning unstable,\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dleWuFb8FWu-",
        "outputId": "019ae670-d782-47ef-beb7-526c267d8599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Softmax without scaling: tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])\n",
            "Softmax after scaling (tensor * 8): tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define the tensor\n",
        "tensor = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
        "\n",
        "# Apply softmax without scaling\n",
        "softmax_result = torch.softmax(tensor, dim=-1)\n",
        "print(\"Softmax without scaling:\", softmax_result)\n",
        "\n",
        "# Multiply the tensor by 8 and then apply softmax\n",
        "scaled_tensor = tensor * 8\n",
        "softmax_scaled_result = torch.softmax(scaled_tensor, dim=-1)\n",
        "print(\"Softmax after scaling (tensor * 8):\", softmax_scaled_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeJtLFBQFWu-"
      },
      "source": [
        "## BUT WHY SQRT?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IKkuR8oFWu-"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Reason 2: To make the variance of the dot product stable\n",
        "\n",
        "The dot product of  Q and K increases the variance because multiplying two random numbers increases the variance.\n",
        "\n",
        "The increase in variance grows with the dimension.\n",
        "\n",
        "Dividing by sqrt (dimension) keeps the variance close to 1\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6q2TrHsoht8"
      },
      "source": [
        "Imagine you’re rolling dice. Consider two cases:\n",
        "\n",
        "Case 1: Rolling one standard die (1–6):\n",
        "\n",
        "The average (mean) is 3.5.\n",
        "The variance is relatively small (≈2.9).\n",
        "You have predictable outcomes.\n",
        "\n",
        "Case 2: Rolling and summing 100 dice:\n",
        "\n",
        "The mean is 100 × 3.5 = 350.\n",
        "The variance significantly grows (100 × 2.9 = 290).\n",
        "Now, outcomes fluctuate widely (e.g., you might get sums like 320, 350, or 380). The distribution spreads out drastically. Outcomes become unpredictable.\n",
        "\n",
        "\n",
        "Dot Product without normalization:\n",
        "\n",
        "Think of dimensions as \"dice.\" Increasing the number of dimensions is like rolling more dice and summing results.\n",
        "Each dimension (dice) contributes some variance. As dimensions grow, variance accumulates.\n",
        "Result: Dot products (before softmax) become either extremely large or small, making attention weights unstable and erratic.\n",
        "\n",
        "Dot Product with normalization (dividing by sqrt(d)):\n",
        "\n",
        "This effectively scales down the variance, ensuring the summed results remain stable.\n",
        "It’s like taking the average roll per dice rather than summing them up, stabilizing your expected outcomes.\n",
        "Result: Attention weights become more stable, predictable, and informative, enabling the model to learn effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCmteApbFWu-",
        "outputId": "970167ae-43b5-40bb-f4fb-dabcccefc340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variance before scaling (dim=5): 4.840529816574412\n",
            "Variance after scaling (dim=5): 0.9681059633148823\n",
            "Variance before scaling (dim=100): 104.52172990736773\n",
            "Variance after scaling (dim=100): 1.0452172990736772\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute variance before and after scaling\n",
        "def compute_variance(dim, num_trials=1000):\n",
        "    dot_products = []\n",
        "    scaled_dot_products = []\n",
        "\n",
        "    # Generate multiple random vectors and compute dot products\n",
        "    for _ in range(num_trials):\n",
        "        q = np.random.randn(dim)\n",
        "        k = np.random.randn(dim)\n",
        "\n",
        "        # Compute dot product\n",
        "        dot_product = np.dot(q, k)\n",
        "        dot_products.append(dot_product)\n",
        "\n",
        "        # Scale the dot product by sqrt(dim)\n",
        "        scaled_dot_product = dot_product / np.sqrt(dim)\n",
        "        scaled_dot_products.append(scaled_dot_product)\n",
        "\n",
        "    # Calculate variance of the dot products\n",
        "    variance_before_scaling = np.var(dot_products)\n",
        "    variance_after_scaling = np.var(scaled_dot_products)\n",
        "\n",
        "    return variance_before_scaling, variance_after_scaling\n",
        "\n",
        "# For dimension 5\n",
        "variance_before_5, variance_after_5 = compute_variance(5)\n",
        "print(f\"Variance before scaling (dim=5): {variance_before_5}\")\n",
        "print(f\"Variance after scaling (dim=5): {variance_after_5}\")\n",
        "\n",
        "# For dimension 20\n",
        "variance_before_100, variance_after_100 = compute_variance(100)\n",
        "print(f\"Variance before scaling (dim=100): {variance_before_100}\")\n",
        "print(f\"Variance after scaling (dim=100): {variance_after_100}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALzKve7MFWu-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "We now compute the context vector as a weighted sum over the value\n",
        "vectors.\n",
        "\n",
        "Here, the attention weights serve as a weighting factor that weighs the respective\n",
        "importance of each value vector.\n",
        "\n",
        "We can use matrix multiplication to\n",
        "obtain the output in one step:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6UlXtZJFWu-",
        "outputId": "4c7de155-04a8-405d-b535-75a381d931ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.3301, 1.5304, 1.8753, 2.3433])\n"
          ]
        }
      ],
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYQP1Lpkp7bb",
        "outputId": "63f1683f-1b77-483d-cb62-c11e8077692f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.3246, 1.5236, 1.8652, 2.3285],\n",
            "        [1.3301, 1.5304, 1.8753, 2.3433],\n",
            "        [1.3325, 1.5353, 1.8866, 2.3537],\n",
            "        [1.3211, 1.5153, 1.8390, 2.3002],\n",
            "        [1.3253, 1.5242, 1.8657, 2.3304]])\n"
          ]
        }
      ],
      "source": [
        "context_vec = attn_weights_final @ values\n",
        "print(context_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTkIifNsFWu-"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "So far, we only computed a single context vector, z(2).\n",
        "\n",
        "In the next section, we will generalize the code to compute all context vectors in the input sequence, z(1)to z (T)</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkFEpcgBFWu-"
      },
      "source": [
        "## IMPLEMENTING A COMPACT SELF ATTENTION PYTHON CLASS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMok9ugmFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "In the previous sections, we have gone through a lot of steps to compute the self-attention\n",
        "outputs.\n",
        "\n",
        "This was mainly done for illustration purposes so we could go through one step at\n",
        "a time.\n",
        "\n",
        "In practice, with the LLM implementation in mind, it is helpful to\n",
        "organize this code into a Python class as follows:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iE1rTSJnFWu_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 0 to 1 step\n",
        "        # causal\n",
        "        # multi-head\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T # omega\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGPCy0GKFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "In this PyTorch code, SelfAttention_v1 is a class derived from nn.Module, which is a\n",
        "fundamental building block of PyTorch models, which provides necessary functionalities for\n",
        "model layer creation and management.    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcviYo_EFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The __init__ method initializes trainable weight matrices (W_query, W_key, and\n",
        "W_value) for queries, keys, and values, each transforming the input dimension d_in to an\n",
        "output dimension d_out.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7noFTezWFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "During the forward pass, using the forward method, we compute the attention scores\n",
        "(attn_scores) by multiplying queries and keys, normalizing these scores using softmax.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN23E2uIFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    \n",
        "Finally, we create a context vector by weighting the values with these normalized attention\n",
        "scores.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQf7sITRFWu_",
        "outputId": "dcaec7ce-e254-42ae-fe20-94c2d527997d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.3246, 1.5236, 1.8652, 2.3285],\n",
            "        [1.3301, 1.5304, 1.8753, 2.3433],\n",
            "        [1.3325, 1.5353, 1.8866, 2.3537],\n",
            "        [1.3211, 1.5153, 1.8390, 2.3002],\n",
            "        [1.3253, 1.5242, 1.8657, 2.3304]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbvndrLAFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Since inputs contains six embedding vectors, we get a matrix storing the six\n",
        "context vectors, as shown in the above result.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NpR1q3tFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "We can improve the SelfAttention_v1 implementation further by utilizing PyTorch's\n",
        "nn.Linear layers, which effectively perform matrix multiplication when the bias units are\n",
        "disabled.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrk9mhMZFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "Additionally, a significant advantage of using nn.Linear instead of manually\n",
        "implementing nn.Parameter(torch.rand(...)) is that nn.Linear has an optimized weight\n",
        "initialization scheme, contributing to more stable and effective model training.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5dBEH325FWu_"
      },
      "outputs": [],
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmDus4CFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "You can use the SelfAttention_v2 similar to SelfAttention_v1:\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WbAZy7wFWu_",
        "outputId": "ed6bf6d1-b10d-4256-de55-222062710bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0174,  0.0553, -0.1093,  0.1026],\n",
            "        [ 0.0175,  0.0556, -0.1089,  0.1024],\n",
            "        [ 0.0175,  0.0559, -0.1087,  0.1022],\n",
            "        [ 0.0179,  0.0544, -0.1091,  0.1028],\n",
            "        [ 0.0172,  0.0543, -0.1105,  0.1032]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(789)\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89, 0.17, 0.23, 0.19, 0.38, 0.44],  # The       (x^1)\n",
        "   [0.55, 0.87, 0.66, 0.51, 0.49, 0.3, 0.2, 0.1],     # next      (x^2)\n",
        "   [0.57, 0.85, 0.64, 0.8, 0.1, 0.4, 0.21, 0.39],     # day       (x^3)\n",
        "   [0.22, 0.58, 0.33, 0.4, 0.4, 0.4, 0.1, 0.3],       # is        (x^4)\n",
        "   [0.77, 0.25, 0.10, 0.1, 0.9, 0.3, 0.3, 0.2]]       # bright    (x^5)\n",
        ")\n",
        "\n",
        "d_in = 8\n",
        "d_out = 4\n",
        "\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYZ-QtmVFWu_"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Note that SelfAttention_v1 and SelfAttention_v2 give different outputs because they\n",
        "use different initial weights for the weight matrices since nn.Linear uses a more\n",
        "sophisticated weight initialization scheme.\n",
        "    \n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
